import os

import streamlit as st
from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI


load_dotenv()


def get_llm_response(input_text: str, expert_choice: str) -> str:
	system_message = ""
	if expert_choice == "A":
		system_message = (
			"ã‚ãªãŸã¯é‹å‹•ã®å°‚é–€å®¶ã§ã™ã€‚å®‰å…¨æ€§ã‚’é‡è¦–ã—ã€å¹´é½¢ãƒ»ä½“åŠ›ãƒ»ç›®çš„ã«"
			"é…æ…®ã—ãŸå®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç°¡æ½”ã«æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚"
		)
	else:
		system_message = (
			"ã‚ãªãŸã¯æ „é¤Šã®å°‚é–€å®¶ã§ã™ã€‚æ „é¤Šãƒãƒ©ãƒ³ã‚¹ã¨ç¶™ç¶šæ€§ã‚’é‡è¦–ã—ã€"
			"å®Ÿè·µã—ã‚„ã™ã„é£Ÿäº‹ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç°¡æ½”ã«æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚"
		)

	prompt = ChatPromptTemplate.from_messages(
		[
			("system", system_message),
			("human", "{user_input}"),
		]
	)

	llm = ChatOpenAI(
		model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
		temperature=0.7,
	)
	chain = prompt | llm | StrOutputParser()
	return chain.invoke({"user_input": input_text})


st.set_page_config(page_title="å°‚é–€å®¶AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", page_icon="ğŸ§ ")
st.title("ğŸ§  å°‚é–€å®¶AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

st.markdown(
	"""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’LLMã«æ¸¡ã—ã¦å°‚é–€å®¶ã¨ã—ã¦ã®å›ç­”ã‚’å¾—ã‚‹ãŸã‚ã®
ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¢ã§ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã§æ“ä½œã§ãã¾ã™ã€‚

1. å°‚é–€å®¶ã®ç¨®é¡ï¼ˆA: é‹å‹• / B: æ „é¤Šï¼‰ã‚’é¸æŠã—ã¾ã™ã€‚
2. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¾ã™ã€‚
3. é€ä¿¡ã™ã‚‹ã¨ã€é¸æŠã—ãŸå°‚é–€å®¶ã¨ã—ã¦ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
"""
)

expert_label = st.radio(
	"å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„",
	options=["A: é‹å‹•ã®å°‚é–€å®¶", "B: æ „é¤Šã®å°‚é–€å®¶"],
	horizontal=True,
)
expert_choice = "A" if expert_label.startswith("A") else "B"

with st.form("input_form"):
	user_input = st.text_area("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ", placeholder="ä¾‹: é€±3å›ã®é‹å‹•ç¿’æ…£ã‚’ä½œã‚ŠãŸã„")
	submitted = st.form_submit_button("é€ä¿¡")

if submitted:
	if not user_input.strip():
		st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
	else:
		with st.spinner("LLMãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
			response = get_llm_response(user_input, expert_choice)
		st.subheader("å›ç­”")
		st.write(response)
